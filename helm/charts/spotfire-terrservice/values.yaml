# Default values for terrservice.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

## @param global.spotfire.image.registry Global Docker image registry
## @param global.spotfire.image.pullSecrets Global Docker registry secret names as an array
##
global:
  spotfire:
    image:
      # global.spotfire.image.registry -- Global container image registry, this will be used for tibco/spotfire container images unless overridden.
      registry:
      # global.spotfire.image.pullPolicy -- Global container image pull policy
      pullPolicy: IfNotPresent
      # global.spotfire.image.pullSecrets -- Global container image pull secrets
      ## E.g.
      ## pullSecrets:
      ##   - myRegistryKeySecretName
      ##  
      pullSecrets: []
  serviceName: terrservice

nodemanagerConfig:
  # -- This should be the spotfire-server service name. This value will be evaluated as a helm template.
  serverBackendAddress: ""
  # -- The draining timeout which after the service is forcefully shutdown
  preStopDrainingTimeoutSeconds: 610

replicaCount: 1

image:
  # image.registry -- image registry for spotfire-server, it overrides global.spotfire.image.registry value.
  registry:
  # image.repository -- spotfire-server image repository
  repository: tibco/spotfire-terrservice
  # image.tag -- The container image tag to be used.
  tag: "1.11.1-alpha3"
  # image.pullPolicy -- spotfire-server image pull policy, It overrides global.spotfire.image.pullPolicy
  pullPolicy:
  ## Optionally specify an array of imagePullSecrets.
  # image.pullSecrets -- spotfire-server image pull secrets
  pullSecrets: []

fluentBit:
  image:
    # -- image repository for fluent-bit logging sidecar.
    repository: fluent/fluent-bit
    # -- image tag to be used for fluent-bit logging sidecar
    tag: "1.8.12"
    # -- image pull policy for the fluent-bit logging sidecar image.
    pullPolicy: IfNotPresent

nameOverride: ""
fullnameOverride: ""

serviceAccount:
  # Specifies whether a service account should be created
  create: false
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

podAnnotations: 
  prometheus.io/path: /spotfire/metrics
  prometheus.io/port: "9080"
  prometheus.io/scrape: "true"

podSecurityContext: {}
  # fsGroup: 2000

securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

service:
  type: ClusterIP
  port: 9501

## Spotfire Nodemanager startup, readiness and liveness probe initial delay and timeout
## Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
startupProbe:
  enabled: true
  httpGet:
    path: /spotfire/started
    port: registration
  initialDelaySeconds: 10
  periodSeconds: 3
  failureThreshold: 30
livenessProbe:
  enabled: true
  httpGet:
    path: /spotfire/liveness
    port: registration
  initialDelaySeconds: 60
  periodSeconds: 3
  failureThreshold: 3
readinessProbe:
  enabled: false
  httpGet:
    path: /spotfire/readiness
    port: registration
  initialDelaySeconds: 60
  periodSeconds: 3
  failureThreshold: 3

logging:
  # -- This should be the spotfire-server log-forwarder name. Template.
  logForwarderAddress: ""
  ## -- set to `debug`, `trace`, `minimal` or leave empty for info
  logLevel: "debug"

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

# -- KEDA autoscaling configuration, see https://keda.sh/docs/2.6/concepts/scaling-deployment for more details.
# @default -- Disabled
kedaAutoscaling:
  enabled: false
  # -- This is the interval to check each trigger on.
  pollingInterval: 30
  # -- The period to wait after the last trigger reported active before scaling the resource back to 0.
  cooldownPeriod: 300
  # -- Minimum number of replicas KEDA will scale the resource down to.
  minReplicas: 1
  # -- This setting is passed to the HPA definition that KEDA will create for a given resource and holds the maximum number of replicas of the target resource.
  maxReplicas: 4
  # threshold: 8
  # fallback: 
  # advanced: 
  # -- Spotfire specific settings
  spotfireConfig:
    # -- REQUIRED The url to the Prometheus server where metrics should be fetched from
    prometheusServerAddress: http://prometheus-server.monitor.svc.cluster.local

nodeSelector: {}

tolerations: []

affinity: {}

config:
  # -- A custom [Spotfire.Dxp.Worker.Automation.config](https://docs.tibco.com/pub/spotfire_server/latest/doc/html/TIB_sfire_server_tsas_admin_help/server/topics/spotfire.dxp.worker.automation.config_file.html)
  conf/custom.properties: ""

  # -- A custom Spotfire.Dxp.Worker.Host.dll.config. See [Spotfire.Dxp.Worker.Host.exe.config](https://docs.tibco.com/pub/spotfire_server/latest/doc/html/TIB_sfire_server_tsas_admin_help/server/topics/spotfire.dxp.worker.host.exe.config_file.html)
  log4j2.xml: ""

  # --
  # appsettings.json:

  # --
  # log4net.config:

# -- Additional environment variables
extraEnvVars: []
#  - name: NAME
#    value: value

# Name of ConfigMap containing additional environment variables
extraEnvVarsCM: ""

# Name of Secret containing extra additional environment variables
extraEnvVarsSecret: ""

# -- Extra volumeMounts for the spotfire-terrservice container.
# More info: `kubectl explain deployment.spec.template.spec.containers.volumeMounts`
extraVolumeMounts: []
  # - name: example
  #   mountPath: /opt/tibco/example.txt
  #   subPath: example.txt

# -- Extra volumes for the spotfire-terrservice container.
# More info: `kubectl explain deployment.spec.template.spec.volumes`
extraVolumes: []
  # - name: example
  #   persistentVolumeClaim:
  #     claimName: exampleClaim

volumes:
  packages:
    name: "packages"
    mountPath: /opt/packages
    persistentVolumeClaim:
      # -- If 'true', then a 'PersistentVolumeClaim' will be created.
      create: false

      # -- Specify the name of the 'StorageClass' that should be used for the customExt volume-claim.
      storageClassName: ""

      # -- Specifies the standard K8s resource requests and/or limits for the customExt volume claims.
      resources:
        requests:
          storage: 1Gi

      # -- Specify the name of the persistent volume that should be used for the customExt volume-claim.
      volumeName:

    # When 'persistentVolumeClaim.create' is 'false', then this value can be used to define already existing
    # persistent volume claim
    customPersistentVolumeClaimName: ""
